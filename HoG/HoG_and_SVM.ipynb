{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Research Project - Poacher Detection: A Machine Learning Approach\n",
        "## Mahdiyah Manjra - 2140796\n",
        "### Superivised BY: Prof. Ewert and Prof.Sanders\n",
        "### HoG Descriptors and Linear Support Vector Classifiers"
      ],
      "metadata": {
        "id": "6zLP7qhWBXz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2CgF4NcBK4s"
      },
      "outputs": [],
      "source": [
        "# import required libraries\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from skimage import img_as_float32 as as_float\n",
        "from skimage.feature import hog\n",
        "import scipy.misc\n",
        "import imageio\n",
        "#from sklearn.externals import joblib\n",
        "import random as rand\n",
        "import numpy as np \n",
        "import cv2\n",
        "import glob\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define different HoG descriptors"
      ],
      "metadata": {
        "id": "LjskkH2rBy7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hogDesc1(image):\n",
        "    features = hog(image, \n",
        "                            orientations = 9, \n",
        "                            pixels_per_cell = (32, 32),\n",
        "                            cells_per_block = (2, 2),\n",
        "                            multichannel=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "hQFsyW49COMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hogDesc2(image):\n",
        "    features = hog(image, \n",
        "                            orientations = 9, \n",
        "                            pixels_per_cell = (32,32),\n",
        "                            cells_per_block = (1, 1),\n",
        "                            multichannel=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "e8SS0OYEqcwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hogDesc3(image):\n",
        "    features = hog(image, \n",
        "                            orientations = 9, \n",
        "                            pixels_per_cell = (16, 16),\n",
        "                            cells_per_block = (1, 1),\n",
        "                            multichannel=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "MFNuWdcYqck-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hogDesc4(image):\n",
        "    features = hog(image, \n",
        "                            orientations = 9, \n",
        "                            pixels_per_cell = (32, 32),\n",
        "                            cells_per_block = (8, 8),\n",
        "                            multichannel=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "o7YypAaUqcb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading and Resizing the data"
      ],
      "metadata": {
        "id": "YwzOsgCvCAxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading images to memory...\")\n",
        "t_start = time.time()\n",
        "\n",
        "human_imgs=[]\n",
        "nonhuman_imgs=[]\n",
        "\n",
        "# read in images from folders\n",
        "human_paths = glob.glob('drive/My Drive/Data_images/test/*.jfif')\n",
        "nonhuman_paths = glob.glob('drive/My Drive/Data_images/nonhumans/*.jfif')\n",
        "\n",
        "#human_imgs = np.array([as_float(imageio.imread(path)) for path in human_paths])\n",
        "#nonhuman_imgs = np.array([as_float(imageio.imread(path)) for path in nonhuman_paths])\n",
        "\n",
        "for path in human_paths: human_imgs.append(imageio.imread(path))\n",
        "for path in nonhuman_paths: nonhuman_imgs.append(imageio.imread(path))\n",
        "\n",
        "# resize images\n",
        "scale = 0.0625\n",
        "\n",
        "human_imgs_rs = [cv2.resize(img, None, fx=scale, fy=scale) for img in human_imgs]\n",
        "nonhuman_imgs_rs = [cv2.resize(img, None, fx=scale, fy=scale) for img in nonhuman_imgs]\n",
        "\n",
        "# save images as array\n",
        "human_imgs1 = np.array(human_imgs_rs, dtype=object)\n",
        "nonhuman_imgs1 = np.array(nonhuman_imgs_rs, dtype=object)\n",
        "\n",
        "# get total number of human and nonhuman images \n",
        "total_humans = human_imgs1.shape[0]\n",
        "total_nonhumans= nonhuman_imgs1.shape[0]\n",
        "\n",
        "print(\"... Done\")\n",
        "print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "print(\"Human images shape: \", human_imgs1.shape)\n",
        "print(\"Non-Human images shape: \", nonhuman_imgs1.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jpRPSC9CJrx",
        "outputId": "8ed4e85b-4b25-45d6-d6db-4f06e8979d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images to memory...\n",
            "... Done\n",
            "Time Taken: 21.22\n",
            "Human images shape:  (26, 96, 128, 3)\n",
            "Non-Human images shape:  (120, 96, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apply SVC on HoG features"
      ],
      "metadata": {
        "id": "_PpEMyzqCmA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,3):\n",
        "\n",
        "  print (\"HOG descriptor: \", i)\n",
        "  print(\"Extracting features...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  human_features, nonhuman_features = [], []\n",
        "\n",
        "  print(\"Humans.....\")\n",
        "  # apply HoG descriptors \n",
        "  for img in human_imgs:\n",
        "\n",
        "    if (i == 1):\n",
        "      features = hogDesc1(img)\n",
        "    elif (i==2):\n",
        "      features = hogDesc2(img)\n",
        "    elif (i==3):\n",
        "      features = hogDesc3(img)\n",
        "    elif (i==4):\n",
        "      features = hogDesc4(img)\n",
        "\n",
        "    human_features.append(features)\n",
        "    print('█', end = '')\n",
        "\n",
        "  print()\n",
        "  print(\"Non-Humans.....\")\n",
        "  # apply HoG descriptors\n",
        "  for img in nonhuman_imgs:\n",
        "\n",
        "    if (i == 1):\n",
        "      features = hogDesc1(img)\n",
        "    elif (i==2):\n",
        "      features = hogDesc2(img)\n",
        "    elif (i==3):\n",
        "      features = hogDesc3(img)\n",
        "    elif (i==4):\n",
        "      features = hogDesc4(img)\n",
        "    nonhuman_features.append(features)\n",
        "    print('█', end = '')\n",
        "\n",
        "  # save features as arrays                     \n",
        "  human_features = np.asarray(human_features)\n",
        "  nonhuman_features = np.asarray(nonhuman_features)\n",
        "\n",
        "  print()\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\"Human features shape: \", human_features.shape)\n",
        "  print(\"Non-humans features shape: \", nonhuman_features.shape)\n",
        "\n",
        "\n",
        "  print(\"Scaling features...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  # standardise the data \n",
        "  unscaled_x = np.vstack((human_features, nonhuman_features)).astype(np.float64)\n",
        "  scaler = StandardScaler().fit(unscaled_x)\n",
        "  x = scaler.transform(unscaled_x)\n",
        "  y = np.hstack((np.ones(total_humans), np.zeros(total_nonhumans)))\n",
        "\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\" x shape: \", x.shape, \" y shape: \", y.shape)\n",
        "\n",
        "\n",
        "  # Training the classifier\n",
        "  print(\"Training classifier...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  # split the data (80% train, 20% test)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.35, random_state = rand.randint(1, 100))\n",
        "\n",
        "  # apply and fit Support Vector Classifier\n",
        "  svc = LinearSVC()\n",
        "  svc.fit(x_train, y_train)\n",
        "\n",
        "  # get performance metrics\n",
        "  accuracy = svc.score(x_test, y_test)\n",
        "  #cv_scores = cross_val_score(svc, x_train, y_train, cv=5)\n",
        "  y_pred = svc.predict(x_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cr = classification_report(y_test, y_pred)\n",
        "\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\"Accuracy: \", np.round(accuracy, 4))\n",
        "  #print(\"CV average score: %.2f\" % cv_scores.mean())\n",
        "  print(cm)\n",
        "  print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ml1z9HUEbO2",
        "outputId": "dbb8e33b-846d-4cb7-f1f5-93737c2b7769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG descriptor:  1\n",
            "Extracting features...\n",
            "Humans.....\n",
            "██████████████████████████\n",
            "Non-Humans.....\n",
            "████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\n",
            "...Done\n",
            "Time Taken: 184.5\n",
            "Human features shape:  (26, 106596)\n",
            "Non-humans features shape:  (120, 106596)\n",
            "Scaling features...\n",
            "...Done\n",
            "Time Taken: 0.34\n",
            " x shape:  (146, 106596)  y shape:  (146,)\n",
            "Training classifier...\n",
            "...Done\n",
            "Time Taken: 3.32\n",
            "Accuracy:  0.7115\n",
            "[[27 15]\n",
            " [ 0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.64      0.78        42\n",
            "         1.0       0.40      1.00      0.57        10\n",
            "\n",
            "    accuracy                           0.71        52\n",
            "   macro avg       0.70      0.82      0.68        52\n",
            "weighted avg       0.88      0.71      0.74        52\n",
            "\n",
            "HOG descriptor:  2\n",
            "Extracting features...\n",
            "Humans.....\n",
            "██████████████████████████\n",
            "Non-Humans.....\n",
            "████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\n",
            "...Done\n",
            "Time Taken: 181.51\n",
            "Human features shape:  (26, 27648)\n",
            "Non-humans features shape:  (120, 27648)\n",
            "Scaling features...\n",
            "...Done\n",
            "Time Taken: 0.1\n",
            " x shape:  (146, 27648)  y shape:  (146,)\n",
            "Training classifier...\n",
            "...Done\n",
            "Time Taken: 0.35\n",
            "Accuracy:  0.7308\n",
            "[[26 14]\n",
            " [ 0 12]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.65      0.79        40\n",
            "         1.0       0.46      1.00      0.63        12\n",
            "\n",
            "    accuracy                           0.73        52\n",
            "   macro avg       0.73      0.82      0.71        52\n",
            "weighted avg       0.88      0.73      0.75        52\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3,5):\n",
        "\n",
        "  print (\"HOG descriptor: \", i)\n",
        "  print(\"Extracting features...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  human_features, nonhuman_features = [], []\n",
        "\n",
        "  print(\"Humans.....\")\n",
        "  # apply HoG descriptors \n",
        "  for img in human_imgs:\n",
        "\n",
        "    if (i == 1):\n",
        "      features = hogDesc1(img)\n",
        "    elif (i==2):\n",
        "      features = hogDesc2(img)\n",
        "    elif (i==3):\n",
        "      features = hogDesc3(img)\n",
        "    elif (i==4):\n",
        "      features = hogDesc4(img)\n",
        "\n",
        "    human_features.append(features)\n",
        "    print('█', end = '')\n",
        "\n",
        "  print()\n",
        "  print(\"Non-Humans.....\")\n",
        "  # apply HoG descriptors\n",
        "  for img in nonhuman_imgs:\n",
        "\n",
        "    if (i == 1):\n",
        "      features = hogDesc1(img)\n",
        "    elif (i==2):\n",
        "      features = hogDesc2(img)\n",
        "    elif (i==3):\n",
        "      features = hogDesc3(img)\n",
        "    elif (i==4):\n",
        "      features = hogDesc4(img)\n",
        "    nonhuman_features.append(features)\n",
        "    print('█', end = '')\n",
        "\n",
        "  # save features as arrays                     \n",
        "  human_features = np.asarray(human_features)\n",
        "  nonhuman_features = np.asarray(nonhuman_features)\n",
        "\n",
        "  print()\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\"Human features shape: \", human_features.shape)\n",
        "  print(\"Non-humans features shape: \", nonhuman_features.shape)\n",
        "\n",
        "\n",
        "  print(\"Scaling features...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  # standardise the data \n",
        "  unscaled_x = np.vstack((human_features, nonhuman_features)).astype(np.float64)\n",
        "  scaler = StandardScaler().fit(unscaled_x)\n",
        "  x = scaler.transform(unscaled_x)\n",
        "  y = np.hstack((np.ones(total_humans), np.zeros(total_nonhumans)))\n",
        "\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\" x shape: \", x.shape, \" y shape: \", y.shape)\n",
        "\n",
        "\n",
        "  # Training the classifier\n",
        "  print(\"Training classifier...\")\n",
        "  t_start = time.time()\n",
        "\n",
        "  # split the data (80% train, 20% test)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.35, random_state = rand.randint(1, 100))\n",
        "\n",
        "  # apply and fit Support Vector Classifier\n",
        "  svc = LinearSVC()\n",
        "  svc.fit(x_train, y_train)\n",
        "\n",
        "  # get performance metrics\n",
        "  accuracy = svc.score(x_test, y_test)\n",
        "  #cv_scores = cross_val_score(svc, x_train, y_train, cv=5)\n",
        "  y_pred = svc.predict(x_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  cr = classification_report(y_test, y_pred)\n",
        "\n",
        "  print(\"...Done\")\n",
        "  print(\"Time Taken:\", np.round(time.time() - t_start, 2))\n",
        "  print(\"Accuracy: \", np.round(accuracy, 4))\n",
        "  #print(\"CV average score: %.2f\" % cv_scores.mean())\n",
        "  print(cm)\n",
        "  print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvKa3Vk7Zrdi",
        "outputId": "d353e6b6-3aed-4970-a16e-208339dea0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG descriptor:  3\n",
            "Extracting features...\n",
            "Humans.....\n",
            "██████████████████████████\n",
            "Non-Humans.....\n",
            "████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\n",
            "...Done\n",
            "Time Taken: 212.92\n",
            "Human features shape:  (26, 110592)\n",
            "Non-humans features shape:  (120, 110592)\n",
            "Scaling features...\n",
            "...Done\n",
            "Time Taken: 0.45\n",
            " x shape:  (146, 110592)  y shape:  (146,)\n",
            "Training classifier...\n",
            "...Done\n",
            "Time Taken: 1.36\n",
            "Accuracy:  0.5962\n",
            "[[20 21]\n",
            " [ 0 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.49      0.66        41\n",
            "         1.0       0.34      1.00      0.51        11\n",
            "\n",
            "    accuracy                           0.60        52\n",
            "   macro avg       0.67      0.74      0.58        52\n",
            "weighted avg       0.86      0.60      0.63        52\n",
            "\n",
            "HOG descriptor:  4\n",
            "Extracting features...\n",
            "Humans.....\n",
            "██████████████████████████\n",
            "Non-Humans.....\n",
            "████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\n",
            "...Done\n",
            "Time Taken: 175.14\n",
            "Human features shape:  (26, 1346112)\n",
            "Non-humans features shape:  (120, 1346112)\n",
            "Scaling features...\n",
            "...Done\n",
            "Time Taken: 3.8\n",
            " x shape:  (146, 1346112)  y shape:  (146,)\n",
            "Training classifier...\n",
            "...Done\n",
            "Time Taken: 68.63\n",
            "Accuracy:  0.75\n",
            "[[29 13]\n",
            " [ 0 10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.69      0.82        42\n",
            "         1.0       0.43      1.00      0.61        10\n",
            "\n",
            "    accuracy                           0.75        52\n",
            "   macro avg       0.72      0.85      0.71        52\n",
            "weighted avg       0.89      0.75      0.78        52\n",
            "\n"
          ]
        }
      ]
    }
  ]
}